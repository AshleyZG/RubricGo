{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import util\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "df = pd.read_csv('test.csv', header = 0, sep = \",\")\n",
    "answers = df.iloc[:,1]\n",
    "student_id = df.iloc[:,0]\n",
    "sentences = []\n",
    "for answer in answers:\n",
    "    sentences.append(answer)\n",
    "bert_embeddings = model.encode(answers)\n",
    "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=2)\n",
    "clustering_model.fit(bert_embeddings)\n",
    "bert_label = clustering_model.labels_\n",
    "\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"id\": student_id,\n",
    "    \"text\": answers,\n",
    "    \"agg_bert_row\": bert_label,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算每一类类中心的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "groups = {}\n",
    "for i in range(0,len(student_id)):\n",
    "    i_cluster = bert_label[i]\n",
    "    if i_cluster not in clusters:\n",
    "        groups[i_cluster] = 1\n",
    "        clusters[i_cluster] = bert_embeddings[i]\n",
    "    else:\n",
    "        groups[i_cluster] +=1\n",
    "        clusters[i_cluster] = clusters[i_cluster] + bert_embeddings[i]\n",
    "# center of the cluster       \n",
    "for key in clusters:\n",
    "    clusters[key] = clusters[key]/groups[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到每一个组的离群点（是否加入老师的input？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8526]])\n",
      "tensor([[0.3395]])\n",
      "tensor([[0.9934]])\n",
      "tensor([[0.9910]])\n",
      "tensor([[0.8349]])\n",
      "tensor([[0.9926]])\n",
      "tensor([[0.8355]])\n",
      "tensor([[0.7568]])\n",
      "tensor([[0.6483]])\n",
      "tensor([[0.6996]])\n",
      "tensor([[0.9452]])\n",
      "tensor([[0.9112]])\n",
      "tensor([[0.8370]])\n",
      "tensor([[0.8483]])\n",
      "tensor([[0.8533]])\n",
      "tensor([[0.7256]])\n",
      "tensor([[0.7659]])\n",
      "tensor([[0.6918]])\n",
      "tensor([[0.6790]])\n",
      "tensor([[0.4895]])\n",
      "tensor([[0.6839]])\n",
      "tensor([[0.6413]])\n",
      "tensor([[0.6538]])\n",
      "tensor([[0.9959]])\n",
      "tensor([[0.9812]])\n",
      "{1: 77, 3: 19, 0: 4, 2: 28, 9: 16, 5: 61, 7: 107, 6: 13, 8: 67, 4: 74}\n"
     ]
    }
   ],
   "source": [
    "distant_point = {}\n",
    "distant_point_id = {}\n",
    "for i in range(0, len(student_id)):\n",
    "    i_cluster = bert_label[i]\n",
    "    cos_sim = util.cos_sim(bert_embeddings[i], clusters[i_cluster])\n",
    "    if i_cluster not in distant_point:\n",
    "        distant_point[i_cluster] = cos_sim\n",
    "        distant_point_id[i_cluster] = i\n",
    "    else:\n",
    "        if(cos_sim < distant_point[i_cluster]):\n",
    "            distant_point[i_cluster] = cos_sim\n",
    "            distant_point_id[i_cluster] = i\n",
    "\n",
    "print(distant_point_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "老师可以在这里选择调整距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [77, 66, 0, 86, 68, 95], 3: [19, 70, 1, 43, 91, 17], 0: [4, 2, 16, 21, 38, 98], 5: [61, 8, 48, 11, 23, 29], 8: [67, 14, 24, 65, 43, 56], 4: [74, 20, 36, 22, 99, 2]}\n",
      "{1: [\"It's important to engage in brainstorming\", 'Brainstorming', 'Radical ideas ', 'One rule for ideation in human-centered design is to defer judgement while you are brainstorming ideas to be able to have an open mind for any ideas that may arise and to not close off any potential solutions.', 'build off of other ideas', 'Building on others ideas'], 3: ['Defer judgement on ideas, DONT judge them too quickly ', 'one rule of ideation is to defer judgement.', 'No judgement', 'Defer judgement means coming up with ideas, not hating on any of them yet.', \"Don't judge ideas to quickly \", \"Don't judge other people's ideas\"], 0: ['Yes and', 'speed dating', 'include all wild ideas too', 'Go for quantity ', 'Go for quantity', 'Go for quantity'], 5: ['be visual; this is to say that human centered design should focus primarily on visual elements', 'Be visual', 'Being visual helps other understand your ideas or suggestions very quickly ', 'Be visual ', 'be visual', 'Be visual'], 8: ['No hate', 'dont judge the idea', 'Dont hate, just come up with ideas dont worry about quality of them yet', 'No such thing as a bad idea', 'Defer judgement means coming up with ideas, not hating on any of them yet.', 'Not think they are me'], 4: ['Consider fron the side of user', 'Know your users, they are not u', 'Know thy users, for they are not you', 'Users are not you', 'You are not the user', 'speed dating']}\n"
     ]
    }
   ],
   "source": [
    "influenced_points = {}\n",
    "for key in distant_point_id:\n",
    "    id = distant_point_id[key]\n",
    "    if(distant_point[key]<0.8):\n",
    "        key_vector = bert_embeddings[id]\n",
    "        key_similarity_list = []\n",
    "        for i in range(0,len(student_id)):\n",
    "            cos_sim = util.cos_sim(bert_embeddings[id], bert_embeddings[i])\n",
    "            key_similarity_list.append(cos_sim)\n",
    "        influenced_points[key] = key_similarity_list\n",
    "\n",
    "most_similar = {}\n",
    "for key in influenced_points:\n",
    "    max_index = []\n",
    "    max_number = heapq.nlargest(6,influenced_points[key]) \n",
    "    for t in max_number:\n",
    "        index = influenced_points[key].index(t)\n",
    "        max_index.append(index)\n",
    "        influenced_points[key][index] = 0\n",
    "    most_similar[key] = max_index\n",
    "print(most_similar)\n",
    "most_similar_answer = {}\n",
    "for key in most_similar:\n",
    "    similar_answers = []\n",
    "    for i in most_similar[key]:\n",
    "        similar_answer = answers[i]\n",
    "        similar_answers.append(similar_answer)\n",
    "    most_similar_answer[key] = similar_answers\n",
    "print(most_similar_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c04fbd425ceb625c68525e86fd94421644b73291a4adf1d6e0e3dc2a4c3bdc6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
